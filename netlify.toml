[build]
  # Build SEO-friendly pre-rendered content before deployment
  command = "node build-seo-content.js"
  
  # Publish the entire src directory
  publish = "src"

# Serve pages with clean URLs
[[redirects]]
  from = "/"
  to = "/pages/index.html"
  status = 200

[[redirects]]
  from = "/about"
  to = "/pages/about.html"
  status = 200

[[redirects]]
  from = "/contact"
  to = "/pages/contact.html"
  status = 200

[[redirects]]
  from = "/quiz"
  to = "/pages/quiz.html"
  status = 200

[[redirects]]
  from = "/store"
  to = "/pages/store.html"
  status = 200

[[redirects]]
  from = "/blog"
  to = "/pages/blog/index.html"
  status = 200

[[redirects]]
  from = "/blog/*"
  to = "/pages/blog/:splat"
  status = 200

# Admin dashboard (password protected)
[[redirects]]
  from = "/admin"
  to = "/pages/admin/dashboard.html"
  status = 200
  force = true

[[redirects]]
  from = "/admin/*"
  to = "/pages/admin/:splat"
  status = 200
  force = true

# Allow direct access to pages folder URLs
[[redirects]]
  from = "/pages/*"
  to = "/pages/:splat"
  status = 200

# Sitemap - must be before catch-all 404
[[redirects]]
  from = "/sitemap.xml"
  to = "/sitemap.xml"
  status = 200

# Robots.txt - must be before catch-all 404
[[redirects]]
  from = "/robots.txt"
  to = "/robots.txt"
  status = 200

# Handle 404 errors - this must be last
[[redirects]]
  from = "/*"
  to = "/pages/404.html"
  status = 404

[[headers]]
  # Sitemap - proper XML content type for search engines
  for = "/sitemap.xml"
  [headers.values]
    Content-Type = "application/xml; charset=utf-8"
    Cache-Control = "public, max-age=3600"

[[headers]]
  # Robots.txt - proper text content type
  for = "/robots.txt"
  [headers.values]
    Content-Type = "text/plain; charset=utf-8"
    Cache-Control = "public, max-age=3600"

[[headers]]
  # Apply security headers to all pages
  for = "/*"
  [headers.values]
    # SECURITY: Force HTTPS for all future visits (HSTS)
    Strict-Transport-Security = "max-age=31536000; includeSubDomains; preload"
    # Prevent clickjacking attacks - DENY is more secure than SAMEORIGIN
    X-Frame-Options = "DENY"
    # Prevent MIME type sniffing
    X-Content-Type-Options = "nosniff"
    # Enable XSS filter built into browsers
    X-XSS-Protection = "1; mode=block"
    # Control referrer information sent to other sites
    Referrer-Policy = "strict-origin-when-cross-origin"
    # Restrict browser features (geolocation, microphone, camera)
    Permissions-Policy = "geolocation=(), microphone=(), camera=(), payment=(), usb=(), magnetometer=(), gyroscope=(), autoplay=()"
    # Content Security Policy - Allow Reddit images and Google Analytics
    Content-Security-Policy = "default-src 'self'; script-src 'self' 'unsafe-inline' https://www.googletagmanager.com https://www.google-analytics.com; style-src 'self' 'unsafe-inline'; img-src 'self' data: https: http:; connect-src 'self' https://www.reddit.com https://old.reddit.com https://www.google-analytics.com https://analytics.google.com; font-src 'self'; frame-ancestors 'none'; base-uri 'self'; form-action 'self'"
